{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bd3663d-b932-4a2f-91a6-a5f2bf630d1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T15:53:48.158647Z",
     "iopub.status.busy": "2022-10-24T15:53:48.158271Z",
     "iopub.status.idle": "2022-10-24T15:53:49.833731Z",
     "shell.execute_reply": "2022-10-24T15:53:49.832832Z",
     "shell.execute_reply.started": "2022-10-24T15:53:48.158576Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports here\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7979a36f-764e-4c2a-8a3c-8cf0369e90b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T15:55:51.841254Z",
     "iopub.status.busy": "2022-10-24T15:55:51.840833Z",
     "iopub.status.idle": "2022-10-24T15:55:51.846323Z",
     "shell.execute_reply": "2022-10-24T15:55:51.845340Z",
     "shell.execute_reply.started": "2022-10-24T15:55:51.841225Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = '/notebooks/flowers'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'\n",
    "#!unzip /flowers.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80b14154-b43a-4503-a23c-aa5abeb39a11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T15:55:52.809133Z",
     "iopub.status.busy": "2022-10-24T15:55:52.808698Z",
     "iopub.status.idle": "2022-10-24T15:55:53.557612Z",
     "shell.execute_reply": "2022-10-24T15:55:53.556839Z",
     "shell.execute_reply.started": "2022-10-24T15:55:52.809102Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Define your transforms for the training, validation, and testing sets\n",
    "#data_transforms =\n",
    "train_dir_transforms = transforms.Compose([transforms.RandomResizedCrop(224), # before all 225 ##256\n",
    "                                           transforms.RandomHorizontalFlip(),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                                [0.229, 0.224, 0.225])])\n",
    "valid_dir_transforms = transforms.Compose([transforms.Resize(224),\n",
    "                                           transforms.CenterCrop(224),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                                [0.229, 0.224, 0.225])])\n",
    "test_dir_transforms = transforms.Compose([transforms.Resize(224),\n",
    "                                          transforms.CenterCrop(224),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                               [0.229, 0.224, 0.225])])\n",
    "\n",
    "# TODO: Load the datasets with ImageFolder\n",
    "#image_datasets = \n",
    "train_data = datasets.ImageFolder(train_dir, train_dir_transforms)\n",
    "valid_set = datasets.ImageFolder(valid_dir, valid_dir_transforms)\n",
    "test_set = datasets.ImageFolder(test_dir, test_dir_transforms)\n",
    "\n",
    "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
    "#dataloaders = \n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size =64, shuffle=True)\n",
    "valid_data = torch.utils.data.DataLoader(valid_set, batch_size=64)\n",
    "test_data = torch.utils.data.DataLoader(test_set, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b568db6d-de68-42f0-a4b0-1092fc43c2e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T15:55:55.687994Z",
     "iopub.status.busy": "2022-10-24T15:55:55.687631Z",
     "iopub.status.idle": "2022-10-24T15:55:55.692903Z",
     "shell.execute_reply": "2022-10-24T15:55:55.692156Z",
     "shell.execute_reply.started": "2022-10-24T15:55:55.687970Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36930fa2-70f4-488e-8e02-58572d0947c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T15:55:58.064157Z",
     "iopub.status.busy": "2022-10-24T15:55:58.063684Z",
     "iopub.status.idle": "2022-10-24T15:56:04.253138Z",
     "shell.execute_reply": "2022-10-24T15:56:04.252256Z",
     "shell.execute_reply.started": "2022-10-24T15:55:58.064125Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3543debc314b37a551ae21be7b7a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/528M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Build and train your network\n",
    "model = models.vgg16(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd15d76c-b7c1-4563-b9e2-546792222a4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T15:56:06.008282Z",
     "iopub.status.busy": "2022-10-24T15:56:06.007873Z",
     "iopub.status.idle": "2022-10-24T15:56:06.118517Z",
     "shell.execute_reply": "2022-10-24T15:56:06.117327Z",
     "shell.execute_reply.started": "2022-10-24T15:56:06.008256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (fc1): Linear(in_features=25088, out_features=320, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (fc2): Linear(in_features=320, out_features=300, bias=True)\n",
      "    (fc3): Linear(in_features=300, out_features=102, bias=True)\n",
      "    (output): LogSoftmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#freeze parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False \n",
    "\n",
    "#new classifier for the feedforward\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "                            ('fc1', nn.Linear(25088, 320)), #4608,320\n",
    "                            ('relu', nn.ReLU()),\n",
    "                            ('dropout', nn.Dropout(0.5)),\n",
    "                            ('fc2', nn.Linear(320, 300)), #320,300\n",
    "                            ('relu', nn.ReLU()),\n",
    "                            ('dropout', nn.Dropout(0.5)),\n",
    "                            ('fc3', nn.Linear(300, 102)), #300,102\n",
    "                            ('output', nn.LogSoftmax(dim=1))\n",
    "                            ]))\n",
    "model.classifier = classifier\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f969b90a-e08d-4a72-9171-0f8ee9c63733",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T16:46:54.229782Z",
     "iopub.status.busy": "2022-10-24T16:46:54.229332Z",
     "iopub.status.idle": "2022-10-24T16:46:54.238195Z",
     "shell.execute_reply": "2022-10-24T16:46:54.237216Z",
     "shell.execute_reply.started": "2022-10-24T16:46:54.229752Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss() #or nn.NLLLoss()CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr =0.000005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1da039b8-b3c2-42e4-860b-8fdbb9424ba5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T16:46:54.884949Z",
     "iopub.status.busy": "2022-10-24T16:46:54.884577Z",
     "iopub.status.idle": "2022-10-24T16:46:54.890677Z",
     "shell.execute_reply": "2022-10-24T16:46:54.889993Z",
     "shell.execute_reply.started": "2022-10-24T16:46:54.884925Z"
    }
   },
   "outputs": [],
   "source": [
    "def validation(model, valid_data, criterion):\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    for images, labels in valid_data:\n",
    "        \n",
    "        images,labels = images.to('cuda'), labels.to('cuda')\n",
    "        \n",
    "        output = model.forward(images)\n",
    "        batch_loss = criterion(output, labels)\n",
    "        test_loss += batch_loss.item()\n",
    "        \n",
    "        ps = torch.exp(output)\n",
    "        equality = (labels.data == ps.max(dim=1)[1])\n",
    "        accuracy += equality.type(torch.FloatTensor).mean()\n",
    "    \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15886d3c-161d-465d-a7e3-8bbf4cda9e0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T17:25:22.542474Z",
     "iopub.status.busy": "2022-10-24T17:25:22.542082Z",
     "iopub.status.idle": "2022-10-24T17:47:56.862764Z",
     "shell.execute_reply": "2022-10-24T17:47:56.861952Z",
     "shell.execute_reply.started": "2022-10-24T17:25:22.542447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/15... Loss: 0.4438 Train Loss: 0.259..  Train Accuracy: 0.940\n",
      "Epoch: 1/15... Loss: 0.4544 Train Loss: 0.260..  Train Accuracy: 0.940\n",
      "Epoch: 2/15... Loss: 0.4592 Train Loss: 0.260..  Train Accuracy: 0.942\n",
      "Epoch: 2/15... Loss: 0.4712 Train Loss: 0.260..  Train Accuracy: 0.942\n",
      "Epoch: 2/15... Loss: 0.4386 Train Loss: 0.259..  Train Accuracy: 0.942\n",
      "Epoch: 3/15... Loss: 0.4409 Train Loss: 0.259..  Train Accuracy: 0.942\n",
      "Epoch: 3/15... Loss: 0.4550 Train Loss: 0.259..  Train Accuracy: 0.940\n",
      "Epoch: 4/15... Loss: 0.4554 Train Loss: 0.258..  Train Accuracy: 0.940\n",
      "Epoch: 4/15... Loss: 0.4519 Train Loss: 0.259..  Train Accuracy: 0.940\n",
      "Epoch: 4/15... Loss: 0.4522 Train Loss: 0.259..  Train Accuracy: 0.940\n",
      "Epoch: 5/15... Loss: 0.4186 Train Loss: 0.258..  Train Accuracy: 0.943\n",
      "Epoch: 5/15... Loss: 0.4251 Train Loss: 0.258..  Train Accuracy: 0.942\n",
      "Epoch: 6/15... Loss: 0.4702 Train Loss: 0.259..  Train Accuracy: 0.942\n",
      "Epoch: 6/15... Loss: 0.4490 Train Loss: 0.259..  Train Accuracy: 0.939\n",
      "Epoch: 6/15... Loss: 0.4339 Train Loss: 0.258..  Train Accuracy: 0.939\n",
      "Epoch: 7/15... Loss: 0.4489 Train Loss: 0.256..  Train Accuracy: 0.942\n",
      "Epoch: 7/15... Loss: 0.4573 Train Loss: 0.255..  Train Accuracy: 0.942\n",
      "Epoch: 7/15... Loss: 0.4201 Train Loss: 0.256..  Train Accuracy: 0.942\n",
      "Epoch: 8/15... Loss: 0.4567 Train Loss: 0.256..  Train Accuracy: 0.942\n",
      "Epoch: 8/15... Loss: 0.4573 Train Loss: 0.258..  Train Accuracy: 0.939\n",
      "Epoch: 9/15... Loss: 0.4248 Train Loss: 0.259..  Train Accuracy: 0.942\n",
      "Epoch: 9/15... Loss: 0.4165 Train Loss: 0.260..  Train Accuracy: 0.940\n",
      "Epoch: 9/15... Loss: 0.4282 Train Loss: 0.258..  Train Accuracy: 0.942\n",
      "Epoch: 10/15... Loss: 0.4494 Train Loss: 0.256..  Train Accuracy: 0.940\n",
      "Epoch: 10/15... Loss: 0.4338 Train Loss: 0.257..  Train Accuracy: 0.939\n",
      "Epoch: 11/15... Loss: 0.4255 Train Loss: 0.256..  Train Accuracy: 0.943\n",
      "Epoch: 11/15... Loss: 0.4313 Train Loss: 0.257..  Train Accuracy: 0.938\n",
      "Epoch: 11/15... Loss: 0.4563 Train Loss: 0.255..  Train Accuracy: 0.939\n",
      "Epoch: 12/15... Loss: 0.4331 Train Loss: 0.255..  Train Accuracy: 0.940\n",
      "Epoch: 12/15... Loss: 0.4444 Train Loss: 0.256..  Train Accuracy: 0.939\n",
      "Epoch: 13/15... Loss: 0.4456 Train Loss: 0.256..  Train Accuracy: 0.939\n",
      "Epoch: 13/15... Loss: 0.4316 Train Loss: 0.255..  Train Accuracy: 0.940\n",
      "Epoch: 13/15... Loss: 0.4492 Train Loss: 0.254..  Train Accuracy: 0.940\n",
      "Epoch: 14/15... Loss: 0.4639 Train Loss: 0.253..  Train Accuracy: 0.940\n",
      "Epoch: 14/15... Loss: 0.4189 Train Loss: 0.254..  Train Accuracy: 0.942\n",
      "Epoch: 14/15... Loss: 0.4612 Train Loss: 0.253..  Train Accuracy: 0.942\n",
      "Epoch: 15/15... Loss: 0.4206 Train Loss: 0.254..  Train Accuracy: 0.942\n",
      "Epoch: 15/15... Loss: 0.4478 Train Loss: 0.254..  Train Accuracy: 0.939\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "print_every = 40\n",
    "steps = 0\n",
    "running_loss = 0 \n",
    "\n",
    "\n",
    "model.to('cuda')\n",
    "\n",
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    #for ii, (inputs,labels) in enumerate(trainloader):\n",
    "    for inputs, labels in trainloader:\n",
    "        steps += 1\n",
    "        \n",
    "        inputs,labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        \n",
    "        #inputs.resize_(inputs.size()[0], 64)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #forward and backward \n",
    "        outputs = model.forward(inputs)\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            # network in eval mode for inference\n",
    "            model.eval()\n",
    "            \n",
    "            # Turn off gradients for validation, saves memory and computations\n",
    "            with torch.no_grad():\n",
    "                test_loss, accuracy = validation(model, valid_data, criterion)\n",
    "                \n",
    "            print(\"Epoch: {}/{}...\".format(e+1,epochs),\n",
    "                  \"Loss: {:.4f}\".format(running_loss/print_every),\n",
    "                  \"Train Loss: {:.3f}.. \".format(test_loss/len(valid_data)),\n",
    "                  \"Train Accuracy: {:.3f}\".format(accuracy/len(valid_data)))\n",
    "            running_loss = 0                    \n",
    "                  \n",
    "                        \n",
    "            # Make sure training is back on\n",
    "            model.train()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8451141f-e52f-4223-b3cf-123080aff333",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T17:21:06.538420Z",
     "iopub.status.busy": "2022-10-24T17:21:06.537909Z",
     "iopub.status.idle": "2022-10-24T17:23:12.317770Z",
     "shell.execute_reply": "2022-10-24T17:23:12.316551Z",
     "shell.execute_reply.started": "2022-10-24T17:21:06.538378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test_data set: 85 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images,labels in test_data:\n",
    "        model.to('cpu')\n",
    "        #images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test_data set: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8769571a-2733-4181-8c94-aa03dea1195a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
