{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffaaf690-ea68-4452-9091-1b2d2eda981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import \n",
    "import json\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import transforms, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from vit_pytorch import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51472309-72fe-4cc6-99a5-37584bad81b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/notebooks/flowers'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'\n",
    "#!unzip /flowers.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85573f26-948e-41dd-b8d5-24f6262947dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define your transforms for the training, validation, and testing sets\n",
    "#data_transforms = # 224 -> 256\n",
    "train_dir_transforms = transforms.Compose([transforms.RandomResizedCrop(224), # before all 225 ##256\n",
    "                                           transforms.RandomHorizontalFlip(),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                                [0.229, 0.224, 0.225])])\n",
    "valid_dir_transforms = transforms.Compose([transforms.Resize(224),\n",
    "                                           transforms.CenterCrop(224),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                                [0.229, 0.224, 0.225])])\n",
    "test_dir_transforms = transforms.Compose([transforms.Resize(224),\n",
    "                                          transforms.CenterCrop(224),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                               [0.229, 0.224, 0.225])])\n",
    "\n",
    "# TODO: Load the datasets with ImageFolder\n",
    "#image_datasets = \n",
    "train_data = ImageFolder(train_dir, train_dir_transforms)\n",
    "valid_set = ImageFolder(valid_dir, valid_dir_transforms)\n",
    "test_set = ImageFolder(test_dir, test_dir_transforms)\n",
    "\n",
    "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
    "#dataloaders = \n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size =64, shuffle=True)\n",
    "valid_data = torch.utils.data.DataLoader(valid_set, batch_size=64)\n",
    "test_data = torch.utils.data.DataLoader(test_set, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49285cf5-d714-4185-a589-5424cf9b2806",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ce89a34-11b5-4e5b-a7d5-394252a06ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.7240, -1.7240, -1.7069,  ..., -1.8953, -1.8953, -1.8610],\n",
       "          [-1.7583, -1.7412, -1.7412,  ..., -1.9124, -1.9124, -1.8953],\n",
       "          [-1.7925, -1.7754, -1.7754,  ..., -1.9295, -1.9295, -1.9124],\n",
       "          ...,\n",
       "          [-1.2274, -1.2617, -1.3130,  ..., -1.6042, -1.2959, -1.0219],\n",
       "          [-1.2274, -1.2959, -1.3473,  ..., -1.4329, -1.0390, -0.6794],\n",
       "          [-1.2445, -1.3130, -1.3473,  ..., -1.1932, -0.6965, -0.2856]],\n",
       " \n",
       "         [[-1.2129, -1.2129, -1.1954,  ..., -1.5630, -1.5630, -1.5980],\n",
       "          [-1.2654, -1.2479, -1.2479,  ..., -1.5980, -1.5980, -1.6331],\n",
       "          [-1.3179, -1.3004, -1.3004,  ..., -1.6331, -1.6331, -1.6506],\n",
       "          ...,\n",
       "          [-0.2500, -0.3025, -0.3725,  ..., -1.1078, -0.7577, -0.3901],\n",
       "          [-0.2325, -0.3025, -0.3901,  ..., -0.8978, -0.4951, -0.0399],\n",
       "          [-0.2675, -0.3375, -0.4251,  ..., -0.6352, -0.1099,  0.3627]],\n",
       " \n",
       "         [[-1.4036, -1.4036, -1.4210,  ..., -1.6302, -1.6302, -1.6127],\n",
       "          [-1.4384, -1.4210, -1.4384,  ..., -1.6650, -1.6650, -1.6476],\n",
       "          [-1.4559, -1.4559, -1.4559,  ..., -1.6999, -1.6999, -1.6824],\n",
       "          ...,\n",
       "          [-1.5779, -1.5604, -1.5779,  ..., -1.6476, -1.5430, -1.4210],\n",
       "          [-1.5953, -1.5953, -1.6127,  ..., -1.5081, -1.3687, -1.1596],\n",
       "          [-1.6302, -1.6302, -1.6302,  ..., -1.4036, -1.1247, -0.8458]]]),\n",
       " 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader.dataset[222]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a20d46a-ad4f-49a3-b21c-44672e915680",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a visual transformer, declaring the number of classes, image size, etc.\n",
    "Make sure that image_size is divisible by patch_size.\n",
    "\"\"\"\n",
    "v = ViT(\n",
    "    image_size = 224,\n",
    "    patch_size = 32, #32\n",
    "    num_classes = 102,\n",
    "    dim = 1024,\n",
    "    depth = 6,\n",
    "    heads = 16,\n",
    "    mlp_dim = 2048,\n",
    "    dropout = 0.5,\n",
    "#    emb_dropout = 0.1\n",
    ")\n",
    "model = ViT(\n",
    "    image_size = 224,\n",
    "    patch_size = 32, #32\n",
    "    num_classes = 102,\n",
    "    dim = 1024,\n",
    "    depth = 6,\n",
    "    heads = 16,\n",
    "    mlp_dim = 2048,\n",
    "    dropout = 0.5,\n",
    "#    emb_dropout = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f8a965d-b243-4014-9052-9ebcf8f12705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, valid_data, criterion):\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    for images, labels in valid_data:\n",
    "        \n",
    "        images,labels = images.to('cuda'), labels.to('cuda')\n",
    "        \n",
    "        output = model.forward(images)\n",
    "        batch_loss = criterion(output, labels)\n",
    "        test_loss += batch_loss.item()\n",
    "        \n",
    "        ps = torch.exp(output)\n",
    "        equality = (labels.data == ps.max(dim=1)[1])\n",
    "        accuracy += equality.type(torch.FloatTensor).mean()\n",
    "    \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b055b74a-a7ec-4da7-a9d6-0dfb6eb485cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/12... Loss: -16722216.0000 Train Loss: -17271040.615..  Train Accuracy: 0.010\n",
      "Epoch: 2/12... Loss: -16778118.0000 Train Loss: -17272690.846..  Train Accuracy: 0.010\n",
      "Epoch: 3/12... Loss: -16169812.0000 Train Loss: -17274327.000..  Train Accuracy: 0.010\n",
      "Epoch: 4/12... Loss: -16568033.0000 Train Loss: -17275953.462..  Train Accuracy: 0.010\n",
      "Epoch: 5/12... Loss: -16972684.0000 Train Loss: -17277569.154..  Train Accuracy: 0.010\n",
      "Epoch: 6/12... Loss: -16875154.0000 Train Loss: -17279184.308..  Train Accuracy: 0.010\n",
      "Epoch: 7/12... Loss: -16685357.0000 Train Loss: -17280798.077..  Train Accuracy: 0.010\n",
      "Epoch: 8/12... Loss: -17100532.0000 Train Loss: -17282406.615..  Train Accuracy: 0.010\n",
      "Epoch: 9/12... Loss: -17020826.0000 Train Loss: -17284019.385..  Train Accuracy: 0.010\n",
      "Epoch: 10/12... Loss: -16190064.0000 Train Loss: -17285622.538..  Train Accuracy: 0.010\n",
      "Epoch: 11/12... Loss: -16778348.0000 Train Loss: -17287221.231..  Train Accuracy: 0.010\n",
      "Epoch: 12/12... Loss: -16917398.0000 Train Loss: -17288817.692..  Train Accuracy: 0.010\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00005)\n",
    "criterion = nn.functional.nll_loss\n",
    "epochs = 12\n",
    "#running_loss = 0\n",
    "model.to('cuda')\n",
    "for epoch in range(epochs):\n",
    "  model.train()\n",
    "  counter = 0\n",
    "  for data in trainloader:\n",
    "    X , y= data\n",
    "    X , y = X.to('cuda'), y.to('cuda')\n",
    "    optimizer.zero_grad() # clear gradient information.\n",
    "    #output = model(X) <- gives errors\n",
    "    output = model.forward(X)\n",
    "    loss = criterion(output, y)\n",
    "    loss.backward() # do pack-propagation step\n",
    "    optimizer.step() # tell optimizer that you finished batch/iteration.\n",
    "    counter += 1\n",
    "    #running_loss += loss.item()\n",
    " \n",
    " \n",
    "  # network in eval mode for inference\n",
    "  model.eval()\n",
    "            \n",
    "  # Turn off gradients for validation, saves memory and computations\n",
    "  with torch.no_grad():\n",
    "      test_loss, accuracy = validation(model, valid_data, criterion)\n",
    "  print(\"Epoch: {}/{}...\".format(epoch+1,epochs),\n",
    "        \"Loss: {:.4f}\".format(loss.data),\n",
    "        \"Train Loss: {:.3f}.. \".format(test_loss/len(valid_data)),\n",
    "        \"Train Accuracy: {:.3f}\".format(accuracy/len(valid_data)))\n",
    "  running_loss = 0\n",
    "  model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5ba0848-a619-46fc-842c-d6e6bca933ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.029\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the trained network.\n",
    "total = 0\n",
    "correct = 0\n",
    "with torch.no_grad():   # No need for keepnig track of necessary changes to the gradient.\n",
    "  for X,y in test_data:\n",
    "    X , y = X.to('cuda'), y.to('cuda')\n",
    "    output = model(X)\n",
    "    for idx, val in enumerate(output):\n",
    "      if torch.argmax(val) == y[idx]:\n",
    "        correct += 1\n",
    "      total += 1\n",
    "  print('Accuracy:', round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ab9858f-9f72-4ab1-8ed5-c822daa163b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-92.1437, device='cuda:0')\n",
      "tensor(-248.3539, device='cuda:0')\n",
      "tensor(-469.9087, device='cuda:0')\n",
      "tensor(-701.1026, device='cuda:0')\n",
      "tensor(-1081.9078, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "optimizer = torch.optim.Adam(v.parameters(), lr=0.001)\n",
    "for epocs in range(5):\n",
    "  v.train()\n",
    "  counter = 0\n",
    "  for data in trainloader:\n",
    "    #print(f\"\\r This is: {counter} of total: {data_length} \",end = \" \")\n",
    "    X , y= data\n",
    "    X , y = X.to('cuda'), y.to('cuda')\n",
    "    optimizer.zero_grad() # clear gradient information.\n",
    "    output = v(X)\n",
    "    loss = nn.functional.nll_loss(output, y)\n",
    "    loss.backward() # do pack-propagation step\n",
    "    optimizer.step() # tell optimizer that you finished batch/iteration.\n",
    "    counter += 1\n",
    "  print(loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f10fe5-676e-4c9d-91a3-9d7f694f03c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
